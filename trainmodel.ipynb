{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87eab26-536d-49be-8414-72cbfd1fb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33866a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fb1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061ae4e6-a221-47b1-bdb1-6275233b2502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646deea3-ef78-4085-8a47-fd8c035930a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b42129-6ca0-4b81-867e-2853b399ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c21e12-f403-4018-9b2e-1bc4ac3db165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72dc397-e6df-4878-a4cd-f0d829b22273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93776788-ee05-4eb6-817c-3856f8b128d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode = \"grayscale\" )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32a5d7-fd6e-441e-b3dd-77933ec4bcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fc99d4ae4b48739c0af462ac5f6951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae305f-66d1-495c-9c50-0a4e4c07c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f945969-3928-4bf9-8d63-e6cd3a80937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2244c-d57c-44d1-ba2e-9a198690f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269f078-4fc3-40e0-84ef-a7c7275306a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0774e21-bd1b-4b0a-a650-5adcf2c82696",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9c02c-08ee-4da2-9c17-5ebc10e36db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28216f6-44b4-4b38-add5-899436e5ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5832fd0-1ca4-4f9b-b63d-ceb04614f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465acc18-fc91-4568-9e38-2a5e16c576d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x= x_train, y= y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddb05d-25f3-4ee1-aedb-43f13d048529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Convert the model to JSON format\n",
    "model_json = model.to_json()\n",
    "\n",
    "# Save the model architecture to a JSON file\n",
    "with open(\"emotiondetection.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights to an H5 file\n",
    "model.save_weights(\"emotiondetection.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde36a4-d1b4-4b88-93d1-952e8f4fc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4ac7a-0001-4580-89e9-2f6b43608576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Open the JSON file containing the model architecture\n",
    "with open(\"emotiondetection.json\", \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "\n",
    "# Load the model architecture from the JSON file\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the model weights from the H5 file\n",
    "model.load_weights(\"emotiondetection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebdc5e-3041-4640-9c4a-e0ac462a2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf9fd3-4c09-4516-8b32-12def79de697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image, color_mode = \"grayscale\" )  # Load grayscale image\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)# Add batch dimension\n",
    "    return feature / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5bc97-af89-4fff-ac9e-9894074ca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"Original image is of sad\")\n",
    "img = ef(image)\n",
    "print(\"Input image shape:\", img.shape)  # Check the shape before prediction\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f519a50-a860-4db1-9abb-e19c0fafa278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0b7e2-e846-4458-8eaf-c9bb197398f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aca2b-889e-48bf-9359-3aac5b66f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/angry/40.jpg'\n",
    "print(\"original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def90918-e6fb-49bc-bda6-07c02a9a9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/fear/2.jpg'\n",
    "print(\"original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abc2db-e796-4b3f-b516-ce8816680612",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/disgust/299.jpg'\n",
    "print(\"original image is of disgust\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be49751-8362-45e1-97e2-4fe0ec0568f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/happy/24.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbeaec-d808-480b-91d5-6784be7c5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'images/train/surprise/52.jpg'\n",
    "print(\"original image is of surprise\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\",pred_label)\n",
    "img = load_img(image, color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac5eb1-d591-451c-84ed-d29d55d50491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1b8c5-bb6e-4f30-8072-30dbd3700164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f9e87-aabf-4a20-9707-aeab6bc5d7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d222ce3-a594-4c7a-91a0-7f2aed842bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bd2cf-4816-466b-b10d-12440e3a4bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946dadd-c278-4c19-a254-3a73c14e0397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
